{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-0.6.0.tar.gz (51 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-0.6.0-py3-none-any.whl size=49720 sha256=9353808f5f503cdb3532ad60f02a06b80643e97dacf69ce6595bb756995603a5\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\4e\\bf\\6b\\2e22b3708d14bf6384f862db539b044d6931bd6b14ad3c9adc\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#step 1 : Get the emoji package\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':1st_place_medal:': '🥇',\n",
       " ':2nd_place_medal:': '🥈',\n",
       " ':3rd_place_medal:': '🥉',\n",
       " ':AB_button_(blood_type):': '🆎',\n",
       " ':ATM_sign:': '🏧',\n",
       " ':A_button_(blood_type):': '🅰',\n",
       " ':A_button_(blood_type)_selector:': '🅰️',\n",
       " ':Afghanistan:': '🇦🇫',\n",
       " ':Aland_Islands:': '🇦🇽',\n",
       " ':Albania:': '🇦🇱',\n",
       " ':Algeria:': '🇩🇿',\n",
       " ':American_Samoa:': '🇦🇸',\n",
       " ':Andorra:': '🇦🇩',\n",
       " ':Angola:': '🇦🇴',\n",
       " ':Anguilla:': '🇦🇮',\n",
       " ':Antarctica:': '🇦🇶',\n",
       " ':Antigua_&_Barbuda:': '🇦🇬',\n",
       " ':Aquarius:': '♒',\n",
       " ':Argentina:': '🇦🇷',\n",
       " ':Aries:': '♈',\n",
       " ':Armenia:': '🇦🇲',\n",
       " ':Aruba:': '🇦🇼',\n",
       " ':Ascension_Island:': '🇦🇨',\n",
       " ':Australia:': '🇦🇺',\n",
       " ':Austria:': '🇦🇹',\n",
       " ':Azerbaijan:': '🇦🇿',\n",
       " ':BACK_arrow:': '🔙',\n",
       " ':B_button_(blood_type):': '🅱',\n",
       " ':B_button_(blood_type)_selector:': '🅱️',\n",
       " ':Bahamas:': '🇧🇸',\n",
       " ':Bahrain:': '🇧🇭',\n",
       " ':Bangladesh:': '🇧🇩',\n",
       " ':Barbados:': '🇧🇧',\n",
       " ':Belarus:': '🇧🇾',\n",
       " ':Belgium:': '🇧🇪',\n",
       " ':Belize:': '🇧🇿',\n",
       " ':Benin:': '🇧🇯',\n",
       " ':Bermuda:': '🇧🇲',\n",
       " ':Bhutan:': '🇧🇹',\n",
       " ':Bolivia:': '🇧🇴',\n",
       " ':Bosnia_&_Herzegovina:': '🇧🇦',\n",
       " ':Botswana:': '🇧🇼',\n",
       " ':Bouvet_Island:': '🇧🇻',\n",
       " ':Brazil:': '🇧🇷',\n",
       " ':British_Indian_Ocean_Territory:': '🇮🇴',\n",
       " ':British_Virgin_Islands:': '🇻🇬',\n",
       " ':Brunei:': '🇧🇳',\n",
       " ':Bulgaria:': '🇧🇬',\n",
       " ':Burkina_Faso:': '🇧🇫',\n",
       " ':Burundi:': '🇧🇮',\n",
       " ':CL_button:': '🆑',\n",
       " ':COOL_button:': '🆒',\n",
       " ':Cambodia:': '🇰🇭',\n",
       " ':Cameroon:': '🇨🇲',\n",
       " ':Canada:': '🇨🇦',\n",
       " ':Canary_Islands:': '🇮🇨',\n",
       " ':Cancer:': '♋',\n",
       " ':Cape_Verde:': '🇨🇻',\n",
       " ':Capricorn:': '♑',\n",
       " ':Caribbean_Netherlands:': '🇧🇶',\n",
       " ':Cayman_Islands:': '🇰🇾',\n",
       " ':Central_African_Republic:': '🇨🇫',\n",
       " ':Ceuta_&_Melilla:': '🇪🇦',\n",
       " ':Chad:': '🇹🇩',\n",
       " ':Chile:': '🇨🇱',\n",
       " ':China:': '🇨🇳',\n",
       " ':Christmas_Island:': '🇨🇽',\n",
       " ':Christmas_tree:': '🎄',\n",
       " ':Clipperton_Island:': '🇨🇵',\n",
       " ':Cocos_(Keeling)_Islands:': '🇨🇨',\n",
       " ':Colombia:': '🇨🇴',\n",
       " ':Comoros:': '🇰🇲',\n",
       " ':Congo_-_Brazzaville:': '🇨🇬',\n",
       " ':Congo_-_Kinshasa:': '🇨🇩',\n",
       " ':Cook_Islands:': '🇨🇰',\n",
       " ':Costa_Rica:': '🇨🇷',\n",
       " ':Croatia:': '🇭🇷',\n",
       " ':Cuba:': '🇨🇺',\n",
       " ':Curaçao:': '🇨🇼',\n",
       " ':Cyprus:': '🇨🇾',\n",
       " ':Czechia:': '🇨🇿',\n",
       " ':Côte_d’Ivoire:': '🇨🇮',\n",
       " ':Denmark:': '🇩🇰',\n",
       " ':Diego_Garcia:': '🇩🇬',\n",
       " ':Djibouti:': '🇩🇯',\n",
       " ':Dominica:': '🇩🇲',\n",
       " ':Dominican_Republic:': '🇩🇴',\n",
       " ':END_arrow:': '🔚',\n",
       " ':Ecuador:': '🇪🇨',\n",
       " ':Egypt:': '🇪🇬',\n",
       " ':El_Salvador:': '🇸🇻',\n",
       " ':England:': '🏴\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f',\n",
       " ':Equatorial_Guinea:': '🇬🇶',\n",
       " ':Eritrea:': '🇪🇷',\n",
       " ':Estonia:': '🇪🇪',\n",
       " ':Ethiopia:': '🇪🇹',\n",
       " ':European_Union:': '🇪🇺',\n",
       " ':FREE_button:': '🆓',\n",
       " ':Falkland_Islands:': '🇫🇰',\n",
       " ':Faroe_Islands:': '🇫🇴',\n",
       " ':Fiji:': '🇫🇯',\n",
       " ':Finland:': '🇫🇮',\n",
       " ':France:': '🇫🇷',\n",
       " ':French_Guiana:': '🇬🇫',\n",
       " ':French_Polynesia:': '🇵🇫',\n",
       " ':French_Southern_Territories:': '🇹🇫',\n",
       " ':Gabon:': '🇬🇦',\n",
       " ':Gambia:': '🇬🇲',\n",
       " ':Gemini:': '♊',\n",
       " ':Georgia:': '🇬🇪',\n",
       " ':Germany:': '🇩🇪',\n",
       " ':Ghana:': '🇬🇭',\n",
       " ':Gibraltar:': '🇬🇮',\n",
       " ':Greece:': '🇬🇷',\n",
       " ':Greenland:': '🇬🇱',\n",
       " ':Grenada:': '🇬🇩',\n",
       " ':Guadeloupe:': '🇬🇵',\n",
       " ':Guam:': '🇬🇺',\n",
       " ':Guatemala:': '🇬🇹',\n",
       " ':Guernsey:': '🇬🇬',\n",
       " ':Guinea-Bissau:': '🇬🇼',\n",
       " ':Guinea:': '🇬🇳',\n",
       " ':Guyana:': '🇬🇾',\n",
       " ':Haiti:': '🇭🇹',\n",
       " ':Heard_&_McDonald_Islands:': '🇭🇲',\n",
       " ':Honduras:': '🇭🇳',\n",
       " ':Hong_Kong_SAR_China:': '🇭🇰',\n",
       " ':Hungary:': '🇭🇺',\n",
       " ':ID_button:': '🆔',\n",
       " ':Iceland:': '🇮🇸',\n",
       " ':India:': '🇮🇳',\n",
       " ':Indonesia:': '🇮🇩',\n",
       " ':Iran:': '🇮🇷',\n",
       " ':Iraq:': '🇮🇶',\n",
       " ':Ireland:': '🇮🇪',\n",
       " ':Isle_of_Man:': '🇮🇲',\n",
       " ':Israel:': '🇮🇱',\n",
       " ':Italy:': '🇮🇹',\n",
       " ':Jamaica:': '🇯🇲',\n",
       " ':Japan:': '🇯🇵',\n",
       " ':Japanese_acceptable_button:': '🉑',\n",
       " ':Japanese_application_button:': '🈸',\n",
       " ':Japanese_bargain_button:': '🉐',\n",
       " ':Japanese_castle:': '🏯',\n",
       " ':Japanese_congratulations_button:': '㊗',\n",
       " ':Japanese_discount_button:': '🈹',\n",
       " ':Japanese_dolls:': '🎎',\n",
       " ':Japanese_free_of_charge_button:': '🈚',\n",
       " ':Japanese_here_button:': '🈁',\n",
       " ':Japanese_monthly_amount_button:': '🈷',\n",
       " ':Japanese_no_vacancy_button:': '🈵',\n",
       " ':Japanese_not_free_of_charge_button:': '🈶',\n",
       " ':Japanese_open_for_business_button:': '🈺',\n",
       " ':Japanese_passing_grade_button:': '🈴',\n",
       " ':Japanese_post_office:': '🏣',\n",
       " ':Japanese_prohibited_button:': '🈲',\n",
       " ':Japanese_reserved_button:': '🈯',\n",
       " ':Japanese_secret_button:': '㊙',\n",
       " ':Japanese_service_charge_button:': '🈂',\n",
       " ':Japanese_symbol_for_beginner:': '🔰',\n",
       " ':Japanese_vacancy_button:': '🈳',\n",
       " ':Japanese_congratulations_button_selector:': '㊗️',\n",
       " ':Japanese_monthly_amount_button_selector:': '🈷️',\n",
       " ':Japanese_secret_button_selector:': '㊙️',\n",
       " ':Japanese_service_charge_button_selector:': '🈂️',\n",
       " ':Jersey:': '🇯🇪',\n",
       " ':Jordan:': '🇯🇴',\n",
       " ':Kazakhstan:': '🇰🇿',\n",
       " ':Kenya:': '🇰🇪',\n",
       " ':Kiribati:': '🇰🇮',\n",
       " ':Kosovo:': '🇽🇰',\n",
       " ':Kuwait:': '🇰🇼',\n",
       " ':Kyrgyzstan:': '🇰🇬',\n",
       " ':Laos:': '🇱🇦',\n",
       " ':Latvia:': '🇱🇻',\n",
       " ':Lebanon:': '🇱🇧',\n",
       " ':Leo:': '♌',\n",
       " ':Lesotho:': '🇱🇸',\n",
       " ':Liberia:': '🇱🇷',\n",
       " ':Libra:': '♎',\n",
       " ':Libya:': '🇱🇾',\n",
       " ':Liechtenstein:': '🇱🇮',\n",
       " ':Lithuania:': '🇱🇹',\n",
       " ':Luxembourg:': '🇱🇺',\n",
       " ':Macau_SAR_China:': '🇲🇴',\n",
       " ':Macedonia:': '🇲🇰',\n",
       " ':Madagascar:': '🇲🇬',\n",
       " ':Malawi:': '🇲🇼',\n",
       " ':Malaysia:': '🇲🇾',\n",
       " ':Maldives:': '🇲🇻',\n",
       " ':Mali:': '🇲🇱',\n",
       " ':Malta:': '🇲🇹',\n",
       " ':Marshall_Islands:': '🇲🇭',\n",
       " ':Martinique:': '🇲🇶',\n",
       " ':Mauritania:': '🇲🇷',\n",
       " ':Mauritius:': '🇲🇺',\n",
       " ':Mayotte:': '🇾🇹',\n",
       " ':Mexico:': '🇲🇽',\n",
       " ':Micronesia:': '🇫🇲',\n",
       " ':Moldova:': '🇲🇩',\n",
       " ':Monaco:': '🇲🇨',\n",
       " ':Mongolia:': '🇲🇳',\n",
       " ':Montenegro:': '🇲🇪',\n",
       " ':Montserrat:': '🇲🇸',\n",
       " ':Morocco:': '🇲🇦',\n",
       " ':Mozambique:': '🇲🇿',\n",
       " ':Mrs._Claus:': '🤶',\n",
       " ':Mrs._Claus_dark_skin_tone:': '🤶🏿',\n",
       " ':Mrs._Claus_light_skin_tone:': '🤶🏻',\n",
       " ':Mrs._Claus_medium-dark_skin_tone:': '🤶🏾',\n",
       " ':Mrs._Claus_medium-light_skin_tone:': '🤶🏼',\n",
       " ':Mrs._Claus_medium_skin_tone:': '🤶🏽',\n",
       " ':Myanmar_(Burma):': '🇲🇲',\n",
       " ':NEW_button:': '🆕',\n",
       " ':NG_button:': '🆖',\n",
       " ':Namibia:': '🇳🇦',\n",
       " ':Nauru:': '🇳🇷',\n",
       " ':Nepal:': '🇳🇵',\n",
       " ':Netherlands:': '🇳🇱',\n",
       " ':New_Caledonia:': '🇳🇨',\n",
       " ':New_Zealand:': '🇳🇿',\n",
       " ':Nicaragua:': '🇳🇮',\n",
       " ':Niger:': '🇳🇪',\n",
       " ':Nigeria:': '🇳🇬',\n",
       " ':Niue:': '🇳🇺',\n",
       " ':Norfolk_Island:': '🇳🇫',\n",
       " ':North_Korea:': '🇰🇵',\n",
       " ':Northern_Mariana_Islands:': '🇲🇵',\n",
       " ':Norway:': '🇳🇴',\n",
       " ':OK_button:': '🆗',\n",
       " ':OK_hand:': '👌',\n",
       " ':OK_hand_dark_skin_tone:': '👌🏿',\n",
       " ':OK_hand_light_skin_tone:': '👌🏻',\n",
       " ':OK_hand_medium-dark_skin_tone:': '👌🏾',\n",
       " ':OK_hand_medium-light_skin_tone:': '👌🏼',\n",
       " ':OK_hand_medium_skin_tone:': '👌🏽',\n",
       " ':ON!_arrow:': '🔛',\n",
       " ':O_button_(blood_type):': '🅾',\n",
       " ':O_button_(blood_type)_selector:': '🅾️',\n",
       " ':Oman:': '🇴🇲',\n",
       " ':Ophiuchus:': '⛎',\n",
       " ':P_button:': '🅿',\n",
       " ':P_button_selector:': '🅿️',\n",
       " ':Pakistan:': '🇵🇰',\n",
       " ':Palau:': '🇵🇼',\n",
       " ':Palestinian_Territories:': '🇵🇸',\n",
       " ':Panama:': '🇵🇦',\n",
       " ':Papua_New_Guinea:': '🇵🇬',\n",
       " ':Paraguay:': '🇵🇾',\n",
       " ':Peru:': '🇵🇪',\n",
       " ':Philippines:': '🇵🇭',\n",
       " ':Pisces:': '♓',\n",
       " ':Pitcairn_Islands:': '🇵🇳',\n",
       " ':Poland:': '🇵🇱',\n",
       " ':Portugal:': '🇵🇹',\n",
       " ':Puerto_Rico:': '🇵🇷',\n",
       " ':Qatar:': '🇶🇦',\n",
       " ':Romania:': '🇷🇴',\n",
       " ':Russia:': '🇷🇺',\n",
       " ':Rwanda:': '🇷🇼',\n",
       " ':Réunion:': '🇷🇪',\n",
       " ':SOON_arrow:': '🔜',\n",
       " ':SOS_button:': '🆘',\n",
       " ':Sagittarius:': '♐',\n",
       " ':Samoa:': '🇼🇸',\n",
       " ':San_Marino:': '🇸🇲',\n",
       " ':Santa_Claus:': '🎅',\n",
       " ':Santa_Claus_dark_skin_tone:': '🎅🏿',\n",
       " ':Santa_Claus_light_skin_tone:': '🎅🏻',\n",
       " ':Santa_Claus_medium-dark_skin_tone:': '🎅🏾',\n",
       " ':Santa_Claus_medium-light_skin_tone:': '🎅🏼',\n",
       " ':Santa_Claus_medium_skin_tone:': '🎅🏽',\n",
       " ':Saudi_Arabia:': '🇸🇦',\n",
       " ':Scorpio:': '♏',\n",
       " ':Scotland:': '🏴\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n",
       " ':Senegal:': '🇸🇳',\n",
       " ':Serbia:': '🇷🇸',\n",
       " ':Seychelles:': '🇸🇨',\n",
       " ':Sierra_Leone:': '🇸🇱',\n",
       " ':Singapore:': '🇸🇬',\n",
       " ':Sint_Maarten:': '🇸🇽',\n",
       " ':Slovakia:': '🇸🇰',\n",
       " ':Slovenia:': '🇸🇮',\n",
       " ':Solomon_Islands:': '🇸🇧',\n",
       " ':Somalia:': '🇸🇴',\n",
       " ':South_Africa:': '🇿🇦',\n",
       " ':South_Georgia_&_South_Sandwich_Islands:': '🇬🇸',\n",
       " ':South_Korea:': '🇰🇷',\n",
       " ':South_Sudan:': '🇸🇸',\n",
       " ':Spain:': '🇪🇸',\n",
       " ':Sri_Lanka:': '🇱🇰',\n",
       " ':St._Barthélemy:': '🇧🇱',\n",
       " ':St._Helena:': '🇸🇭',\n",
       " ':St._Kitts_&_Nevis:': '🇰🇳',\n",
       " ':St._Lucia:': '🇱🇨',\n",
       " ':St._Martin:': '🇲🇫',\n",
       " ':St._Pierre_&_Miquelon:': '🇵🇲',\n",
       " ':St._Vincent_&_Grenadines:': '🇻🇨',\n",
       " ':Statue_of_Liberty:': '🗽',\n",
       " ':Sudan:': '🇸🇩',\n",
       " ':Suriname:': '🇸🇷',\n",
       " ':Svalbard_&_Jan_Mayen:': '🇸🇯',\n",
       " ':Swaziland:': '🇸🇿',\n",
       " ':Sweden:': '🇸🇪',\n",
       " ':Switzerland:': '🇨🇭',\n",
       " ':Syria:': '🇸🇾',\n",
       " ':São_Tomé_&_Príncipe:': '🇸🇹',\n",
       " ':T-Rex:': '🦖',\n",
       " ':TOP_arrow:': '🔝',\n",
       " ':Taiwan:': '🇹🇼',\n",
       " ':Tajikistan:': '🇹🇯',\n",
       " ':Tanzania:': '🇹🇿',\n",
       " ':Taurus:': '♉',\n",
       " ':Thailand:': '🇹🇭',\n",
       " ':Timor-Leste:': '🇹🇱',\n",
       " ':Togo:': '🇹🇬',\n",
       " ':Tokelau:': '🇹🇰',\n",
       " ':Tokyo_tower:': '🗼',\n",
       " ':Tonga:': '🇹🇴',\n",
       " ':Trinidad_&_Tobago:': '🇹🇹',\n",
       " ':Tristan_da_Cunha:': '🇹🇦',\n",
       " ':Tunisia:': '🇹🇳',\n",
       " ':Turkey:': '🇹🇷',\n",
       " ':Turkmenistan:': '🇹🇲',\n",
       " ':Turks_&_Caicos_Islands:': '🇹🇨',\n",
       " ':Tuvalu:': '🇹🇻',\n",
       " ':U.S._Outlying_Islands:': '🇺🇲',\n",
       " ':U.S._Virgin_Islands:': '🇻🇮',\n",
       " ':UP!_button:': '🆙',\n",
       " ':Uganda:': '🇺🇬',\n",
       " ':Ukraine:': '🇺🇦',\n",
       " ':United_Arab_Emirates:': '🇦🇪',\n",
       " ':United_Kingdom:': '🇬🇧',\n",
       " ':United_Nations:': '🇺🇳',\n",
       " ':United_States:': '🇺🇸',\n",
       " ':Uruguay:': '🇺🇾',\n",
       " ':Uzbekistan:': '🇺🇿',\n",
       " ':VS_button:': '🆚',\n",
       " ':Vanuatu:': '🇻🇺',\n",
       " ':Vatican_City:': '🇻🇦',\n",
       " ':Venezuela:': '🇻🇪',\n",
       " ':Vietnam:': '🇻🇳',\n",
       " ':Virgo:': '♍',\n",
       " ':Wales:': '🏴\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n",
       " ':Wallis_&_Futuna:': '🇼🇫',\n",
       " ':Western_Sahara:': '🇪🇭',\n",
       " ':Yemen:': '🇾🇪',\n",
       " ':Zambia:': '🇿🇲',\n",
       " ':Zimbabwe:': '🇿🇼',\n",
       " ':abacus:': '🧮',\n",
       " ':adhesive_bandage:': '\\U0001fa79',\n",
       " ':admission_tickets:': '🎟',\n",
       " ':admission_tickets_selector:': '🎟️',\n",
       " ':adult:': '🧑',\n",
       " ':adult_dark_skin_tone:': '🧑🏿',\n",
       " ':adult_light_skin_tone:': '🧑🏻',\n",
       " ':adult_medium-dark_skin_tone:': '🧑🏾',\n",
       " ':adult_medium-light_skin_tone:': '🧑🏼',\n",
       " ':adult_medium_skin_tone:': '🧑🏽',\n",
       " ':aerial_tramway:': '🚡',\n",
       " ':airplane:': '✈',\n",
       " ':airplane_arrival:': '🛬',\n",
       " ':airplane_departure:': '🛫',\n",
       " ':airplane_selector:': '✈️',\n",
       " ':alarm_clock:': '⏰',\n",
       " ':alembic:': '⚗',\n",
       " ':alembic_selector:': '⚗️',\n",
       " ':alien:': '👽',\n",
       " ':alien_monster:': '👾',\n",
       " ':ambulance:': '🚑',\n",
       " ':american_football:': '🏈',\n",
       " ':amphora:': '🏺',\n",
       " ':anchor:': '⚓',\n",
       " ':anger_symbol:': '💢',\n",
       " ':angry_face:': '😠',\n",
       " ':angry_face_with_horns:': '👿',\n",
       " ':anguished_face:': '😧',\n",
       " ':ant:': '🐜',\n",
       " ':antenna_bars:': '📶',\n",
       " ':anxious_face_with_sweat:': '😰',\n",
       " ':articulated_lorry:': '🚛',\n",
       " ':artist_palette:': '🎨',\n",
       " ':astonished_face:': '😲',\n",
       " ':atom_symbol:': '⚛',\n",
       " ':atom_symbol_selector:': '⚛️',\n",
       " ':auto_rickshaw:': '\\U0001f6fa',\n",
       " ':automobile:': '🚗',\n",
       " ':avocado:': '🥑',\n",
       " ':axe:': '\\U0001fa93',\n",
       " ':baby:': '👶',\n",
       " ':baby_angel:': '👼',\n",
       " ':baby_angel_dark_skin_tone:': '👼🏿',\n",
       " ':baby_angel_light_skin_tone:': '👼🏻',\n",
       " ':baby_angel_medium-dark_skin_tone:': '👼🏾',\n",
       " ':baby_angel_medium-light_skin_tone:': '👼🏼',\n",
       " ':baby_angel_medium_skin_tone:': '👼🏽',\n",
       " ':baby_bottle:': '🍼',\n",
       " ':baby_chick:': '🐤',\n",
       " ':baby_dark_skin_tone:': '👶🏿',\n",
       " ':baby_light_skin_tone:': '👶🏻',\n",
       " ':baby_medium-dark_skin_tone:': '👶🏾',\n",
       " ':baby_medium-light_skin_tone:': '👶🏼',\n",
       " ':baby_medium_skin_tone:': '👶🏽',\n",
       " ':baby_symbol:': '🚼',\n",
       " ':backhand_index_pointing_down:': '👇',\n",
       " ':backhand_index_pointing_down_dark_skin_tone:': '👇🏿',\n",
       " ':backhand_index_pointing_down_light_skin_tone:': '👇🏻',\n",
       " ':backhand_index_pointing_down_medium-dark_skin_tone:': '👇🏾',\n",
       " ':backhand_index_pointing_down_medium-light_skin_tone:': '👇🏼',\n",
       " ':backhand_index_pointing_down_medium_skin_tone:': '👇🏽',\n",
       " ':backhand_index_pointing_left:': '👈',\n",
       " ':backhand_index_pointing_left_dark_skin_tone:': '👈🏿',\n",
       " ':backhand_index_pointing_left_light_skin_tone:': '👈🏻',\n",
       " ':backhand_index_pointing_left_medium-dark_skin_tone:': '👈🏾',\n",
       " ':backhand_index_pointing_left_medium-light_skin_tone:': '👈🏼',\n",
       " ':backhand_index_pointing_left_medium_skin_tone:': '👈🏽',\n",
       " ':backhand_index_pointing_right:': '👉',\n",
       " ':backhand_index_pointing_right_dark_skin_tone:': '👉🏿',\n",
       " ':backhand_index_pointing_right_light_skin_tone:': '👉🏻',\n",
       " ':backhand_index_pointing_right_medium-dark_skin_tone:': '👉🏾',\n",
       " ':backhand_index_pointing_right_medium-light_skin_tone:': '👉🏼',\n",
       " ':backhand_index_pointing_right_medium_skin_tone:': '👉🏽',\n",
       " ':backhand_index_pointing_up:': '👆',\n",
       " ':backhand_index_pointing_up_dark_skin_tone:': '👆🏿',\n",
       " ':backhand_index_pointing_up_light_skin_tone:': '👆🏻',\n",
       " ':backhand_index_pointing_up_medium-dark_skin_tone:': '👆🏾',\n",
       " ':backhand_index_pointing_up_medium-light_skin_tone:': '👆🏼',\n",
       " ':backhand_index_pointing_up_medium_skin_tone:': '👆🏽',\n",
       " ':bacon:': '🥓',\n",
       " ':badger:': '🦡',\n",
       " ':badminton:': '🏸',\n",
       " ':bagel:': '🥯',\n",
       " ':baggage_claim:': '🛄',\n",
       " ':baguette_bread:': '🥖',\n",
       " ':balance_scale:': '⚖',\n",
       " ':balance_scale_selector:': '⚖️',\n",
       " ':bald:': '🦲',\n",
       " ':bald_man:': '👨\\u200d🦲',\n",
       " ':bald_woman:': '👩\\u200d🦲',\n",
       " ':ballet_shoes:': '\\U0001fa70',\n",
       " ':balloon:': '🎈',\n",
       " ':ballot_box_with_ballot:': '🗳',\n",
       " ':ballot_box_with_ballot_selector:': '🗳️',\n",
       " ':ballot_box_with_check:': '☑',\n",
       " ':banana:': '🍌',\n",
       " ':banjo:': '\\U0001fa95',\n",
       " ':bank:': '🏦',\n",
       " ':bar_chart:': '📊',\n",
       " ':barber_pole:': '💈',\n",
       " ':baseball:': '⚾',\n",
       " ':basket:': '🧺',\n",
       " ':basketball:': '🏀',\n",
       " ':bat:': '🦇',\n",
       " ':bathtub:': '🛁',\n",
       " ':battery:': '🔋',\n",
       " ':beach_with_umbrella:': '🏖',\n",
       " ':beach_with_umbrella_selector:': '🏖️',\n",
       " ':beaming_face_with_smiling_eyes:': '😁',\n",
       " ':bear_face:': '🐻',\n",
       " ':bearded_person:': '🧔',\n",
       " ':bearded_person_dark_skin_tone:': '🧔🏿',\n",
       " ':bearded_person_light_skin_tone:': '🧔🏻',\n",
       " ':bearded_person_medium-dark_skin_tone:': '🧔🏾',\n",
       " ':bearded_person_medium-light_skin_tone:': '🧔🏼',\n",
       " ':bearded_person_medium_skin_tone:': '🧔🏽',\n",
       " ':beating_heart:': '💓',\n",
       " ':bed:': '🛏',\n",
       " ':bed_selector:': '🛏️',\n",
       " ':beer_mug:': '🍺',\n",
       " ':bell:': '🔔',\n",
       " ':bell_with_slash:': '🔕',\n",
       " ':bellhop_bell:': '🛎',\n",
       " ':bellhop_bell_selector:': '🛎️',\n",
       " ':bento_box:': '🍱',\n",
       " ':beverage_box:': '\\U0001f9c3',\n",
       " ':bicycle:': '🚲',\n",
       " ':bikini:': '👙',\n",
       " ':billed_cap:': '🧢',\n",
       " ':biohazard:': '☣',\n",
       " ':biohazard_selector:': '☣️',\n",
       " ':bird:': '🐦',\n",
       " ':birthday_cake:': '🎂',\n",
       " ':black_circle:': '⚫',\n",
       " ':black_flag:': '🏴',\n",
       " ':black_heart:': '🖤',\n",
       " ':black_large_square:': '⬛',\n",
       " ':black_medium-small_square:': '◾',\n",
       " ':black_medium_square:': '◼',\n",
       " ':black_medium_square_selector:': '◼️',\n",
       " ':black_nib:': '✒',\n",
       " ':black_nib_selector:': '✒️',\n",
       " ':black_small_square:': '▪',\n",
       " ':black_small_square_selector:': '▪️',\n",
       " ':black_square_button:': '🔲',\n",
       " ':blond-haired_man:': '👱\\u200d♂️',\n",
       " ':blond-haired_man_dark_skin_tone:': '👱🏿\\u200d♂️',\n",
       " ':blond-haired_man_light_skin_tone:': '👱🏻\\u200d♂️',\n",
       " ':blond-haired_man_medium-dark_skin_tone:': '👱🏾\\u200d♂️',\n",
       " ':blond-haired_man_medium-light_skin_tone:': '👱🏼\\u200d♂️',\n",
       " ':blond-haired_man_medium_skin_tone:': '👱🏽\\u200d♂️',\n",
       " ':blond-haired_person:': '👱',\n",
       " ':blond-haired_person_dark_skin_tone:': '👱🏿',\n",
       " ':blond-haired_person_light_skin_tone:': '👱🏻',\n",
       " ':blond-haired_person_medium-dark_skin_tone:': '👱🏾',\n",
       " ':blond-haired_person_medium-light_skin_tone:': '👱🏼',\n",
       " ':blond-haired_person_medium_skin_tone:': '👱🏽',\n",
       " ':blond-haired_woman:': '👱\\u200d♀️',\n",
       " ':blond-haired_woman_dark_skin_tone:': '👱🏿\\u200d♀️',\n",
       " ':blond-haired_woman_light_skin_tone:': '👱🏻\\u200d♀️',\n",
       " ':blond-haired_woman_medium-dark_skin_tone:': '👱🏾\\u200d♀️',\n",
       " ':blond-haired_woman_medium-light_skin_tone:': '👱🏼\\u200d♀️',\n",
       " ':blond-haired_woman_medium_skin_tone:': '👱🏽\\u200d♀️',\n",
       " ':blossom:': '🌼',\n",
       " ':blowfish:': '🐡',\n",
       " ':blue_book:': '📘',\n",
       " ':blue_circle:': '🔵',\n",
       " ':blue_heart:': '💙',\n",
       " ':blue_square:': '\\U0001f7e6',\n",
       " ':boar:': '🐗',\n",
       " ':bomb:': '💣',\n",
       " ':bone:': '🦴',\n",
       " ':bookmark:': '🔖',\n",
       " ':bookmark_tabs:': '📑',\n",
       " ':books:': '📚',\n",
       " ':bottle_with_popping_cork:': '🍾',\n",
       " ':bouquet:': '💐',\n",
       " ':bow_and_arrow:': '🏹',\n",
       " ':bowl_with_spoon:': '🥣',\n",
       " ':bowling:': '🎳',\n",
       " ':boxing_glove:': '🥊',\n",
       " ':boy:': '👦',\n",
       " ':boy_dark_skin_tone:': '👦🏿',\n",
       " ':boy_light_skin_tone:': '👦🏻',\n",
       " ':boy_medium-dark_skin_tone:': '👦🏾',\n",
       " ':boy_medium-light_skin_tone:': '👦🏼',\n",
       " ':boy_medium_skin_tone:': '👦🏽',\n",
       " ':brain:': '🧠',\n",
       " ':bread:': '🍞',\n",
       " ':breast-feeding:': '🤱',\n",
       " ':breast-feeding_dark_skin_tone:': '🤱🏿',\n",
       " ':breast-feeding_light_skin_tone:': '🤱🏻',\n",
       " ':breast-feeding_medium-dark_skin_tone:': '🤱🏾',\n",
       " ':breast-feeding_medium-light_skin_tone:': '🤱🏼',\n",
       " ':breast-feeding_medium_skin_tone:': '🤱🏽',\n",
       " ':brick:': '🧱',\n",
       " ':bride_with_veil:': '👰',\n",
       " ':bride_with_veil_dark_skin_tone:': '👰🏿',\n",
       " ':bride_with_veil_light_skin_tone:': '👰🏻',\n",
       " ':bride_with_veil_medium-dark_skin_tone:': '👰🏾',\n",
       " ':bride_with_veil_medium-light_skin_tone:': '👰🏼',\n",
       " ':bride_with_veil_medium_skin_tone:': '👰🏽',\n",
       " ':bridge_at_night:': '🌉',\n",
       " ':briefcase:': '💼',\n",
       " ':briefs:': '\\U0001fa72',\n",
       " ':bright_button:': '🔆',\n",
       " ':broccoli:': '🥦',\n",
       " ':broken_heart:': '💔',\n",
       " ':broom:': '🧹',\n",
       " ':brown_circle:': '\\U0001f7e4',\n",
       " ':brown_heart:': '\\U0001f90e',\n",
       " ':brown_square:': '\\U0001f7eb',\n",
       " ':bug:': '🐛',\n",
       " ':building_construction:': '🏗',\n",
       " ':building_construction_selector:': '🏗️',\n",
       " ':bullet_train:': '🚅',\n",
       " ':burrito:': '🌯',\n",
       " ':bus:': '🚌',\n",
       " ':bus_stop:': '🚏',\n",
       " ':bust_in_silhouette:': '👤',\n",
       " ':busts_in_silhouette:': '👥',\n",
       " ':butter:': '\\U0001f9c8',\n",
       " ':butterfly:': '🦋',\n",
       " ':cactus:': '🌵',\n",
       " ':calendar:': '📅',\n",
       " ':call_me_hand:': '🤙',\n",
       " ':call_me_hand_dark_skin_tone:': '🤙🏿',\n",
       " ':call_me_hand_light_skin_tone:': '🤙🏻',\n",
       " ':call_me_hand_medium-dark_skin_tone:': '🤙🏾',\n",
       " ':call_me_hand_medium-light_skin_tone:': '🤙🏼',\n",
       " ':call_me_hand_medium_skin_tone:': '🤙🏽',\n",
       " ':camel:': '🐪',\n",
       " ':camera:': '📷',\n",
       " ':camera_with_flash:': '📸',\n",
       " ':camping:': '🏕',\n",
       " ':camping_selector:': '🏕️',\n",
       " ':candle:': '🕯',\n",
       " ':candle_selector:': '🕯️',\n",
       " ':candy:': '🍬',\n",
       " ':canned_food:': '🥫',\n",
       " ':canoe:': '🛶',\n",
       " ':card_file_box:': '🗃',\n",
       " ':card_file_box_selector:': '🗃️',\n",
       " ':card_index:': '📇',\n",
       " ':card_index_dividers:': '🗂',\n",
       " ':card_index_dividers_selector:': '🗂️',\n",
       " ':carousel_horse:': '🎠',\n",
       " ':carp_streamer:': '🎏',\n",
       " ':carrot:': '🥕',\n",
       " ':castle:': '🏰',\n",
       " ':cat:': '🐈',\n",
       " ':cat_face:': '🐱',\n",
       " ':cat_face_with_tears_of_joy:': '😹',\n",
       " ':cat_face_with_wry_smile:': '😼',\n",
       " ':chains:': '⛓',\n",
       " ':chains_selector:': '⛓️',\n",
       " ':chair:': '\\U0001fa91',\n",
       " ':chart_decreasing:': '📉',\n",
       " ':chart_increasing:': '📈',\n",
       " ':chart_increasing_with_yen:': '💹',\n",
       " ':check_box_with_check:': '☑️',\n",
       " ':check_mark:': '✔️',\n",
       " ':cheese_wedge:': '🧀',\n",
       " ':chequered_flag:': '🏁',\n",
       " ':cherries:': '🍒',\n",
       " ':cherry_blossom:': '🌸',\n",
       " ':chess_pawn:': '♟',\n",
       " ':chess_pawn_selector:': '♟️',\n",
       " ':chestnut:': '🌰',\n",
       " ':chicken:': '🐔',\n",
       " ':child:': '🧒',\n",
       " ':child_dark_skin_tone:': '🧒🏿',\n",
       " ':child_light_skin_tone:': '🧒🏻',\n",
       " ':child_medium-dark_skin_tone:': '🧒🏾',\n",
       " ':child_medium-light_skin_tone:': '🧒🏼',\n",
       " ':child_medium_skin_tone:': '🧒🏽',\n",
       " ':children_crossing:': '🚸',\n",
       " ':chipmunk:': '🐿',\n",
       " ':chipmunk_selector:': '🐿️',\n",
       " ':chocolate_bar:': '🍫',\n",
       " ':chopsticks:': '🥢',\n",
       " ':church:': '⛪',\n",
       " ':cigarette:': '🚬',\n",
       " ':cinema:': '🎦',\n",
       " ':circled_M:': 'Ⓜ',\n",
       " ':circled_M_selector:': 'Ⓜ️',\n",
       " ':circus_tent:': '🎪',\n",
       " ':cityscape:': '🏙',\n",
       " ':cityscape_at_dusk:': '🌆',\n",
       " ':cityscape_selector:': '🏙️',\n",
       " ':clamp:': '🗜',\n",
       " ':clamp_selector:': '🗜️',\n",
       " ':clapper_board:': '🎬',\n",
       " ':clapping_hands:': '👏',\n",
       " ':clapping_hands_dark_skin_tone:': '👏🏿',\n",
       " ':clapping_hands_light_skin_tone:': '👏🏻',\n",
       " ':clapping_hands_medium-dark_skin_tone:': '👏🏾',\n",
       " ':clapping_hands_medium-light_skin_tone:': '👏🏼',\n",
       " ':clapping_hands_medium_skin_tone:': '👏🏽',\n",
       " ':classical_building:': '🏛',\n",
       " ':classical_building_selector:': '🏛️',\n",
       " ':clinking_beer_mugs:': '🍻',\n",
       " ':clinking_glasses:': '🥂',\n",
       " ':clipboard:': '📋',\n",
       " ':clockwise_vertical_arrows:': '🔃',\n",
       " ':closed_book:': '📕',\n",
       " ':closed_mailbox_with_lowered_flag:': '📪',\n",
       " ':closed_mailbox_with_raised_flag:': '📫',\n",
       " ':closed_umbrella:': '🌂',\n",
       " ':cloud:': '☁',\n",
       " ':cloud_selector:': '☁️',\n",
       " ':cloud_with_lightning:': '🌩',\n",
       " ':cloud_with_lightning_and_rain:': '⛈',\n",
       " ':cloud_with_lightning_and_rain_selector:': '⛈️',\n",
       " ':cloud_with_lightning_selector:': '🌩️',\n",
       " ':cloud_with_rain:': '🌧',\n",
       " ':cloud_with_rain_selector:': '🌧️',\n",
       " ':cloud_with_snow:': '🌨',\n",
       " ':cloud_with_snow_selector:': '🌨️',\n",
       " ':clown_face:': '🤡',\n",
       " ':club_suit:': '♣',\n",
       " ':club_suit_selector:': '♣️',\n",
       " ':clutch_bag:': '👝',\n",
       " ':coat:': '🧥',\n",
       " ':cocktail_glass:': '🍸',\n",
       " ':coconut:': '🥥',\n",
       " ':coffin:': '⚰',\n",
       " ':coffin_selector:': '⚰️',\n",
       " ':cold_face:': '🥶',\n",
       " ':collision:': '💥',\n",
       " ':comet:': '☄',\n",
       " ':comet_selector:': '☄️',\n",
       " ':compass:': '🧭',\n",
       " ':computer_disk:': '💽',\n",
       " ':computer_mouse:': '🖱',\n",
       " ':computer_mouse_selector:': '🖱️',\n",
       " ':confetti_ball:': '🎊',\n",
       " ':confounded_face:': '😖',\n",
       " ':confused_face:': '😕',\n",
       " ':construction:': '🚧',\n",
       " ':construction_worker:': '👷',\n",
       " ':construction_worker_dark_skin_tone:': '👷🏿',\n",
       " ':construction_worker_light_skin_tone:': '👷🏻',\n",
       " ':construction_worker_medium-dark_skin_tone:': '👷🏾',\n",
       " ':construction_worker_medium-light_skin_tone:': '👷🏼',\n",
       " ':construction_worker_medium_skin_tone:': '👷🏽',\n",
       " ':control_knobs:': '🎛',\n",
       " ':control_knobs_selector:': '🎛️',\n",
       " ':convenience_store:': '🏪',\n",
       " ':cooked_rice:': '🍚',\n",
       " ':cookie:': '🍪',\n",
       " ':cooking:': '🍳',\n",
       " ':copyright:': '©',\n",
       " ':copyright_selector:': '©️',\n",
       " ':couch_and_lamp:': '🛋',\n",
       " ':couch_and_lamp_selector:': '🛋️',\n",
       " ':counterclockwise_arrows_button:': '🔄',\n",
       " ':couple_with_heart-man-man:': '👨\\u200d❤\\u200d👨',\n",
       " ':couple_with_heart-woman-man:': '👩\\u200d❤\\u200d👨',\n",
       " ':couple_with_heart-woman-woman:': '👩\\u200d❤\\u200d👩',\n",
       " ':couple_with_heart:': '💑',\n",
       " ':couple_with_heart_man_man:': '👨\\u200d❤️\\u200d👨',\n",
       " ':couple_with_heart_woman_man:': '👩\\u200d❤️\\u200d👨',\n",
       " ':couple_with_heart_woman_woman:': '👩\\u200d❤️\\u200d👩',\n",
       " ':cow:': '🐄',\n",
       " ':cow_face:': '🐮',\n",
       " ':cowboy_hat_face:': '🤠',\n",
       " ':crab:': '🦀',\n",
       " ':crayon:': '🖍',\n",
       " ':crayon_selector:': '🖍️',\n",
       " ':credit_card:': '💳',\n",
       " ':crescent_moon:': '🌙',\n",
       " ':cricket:': '🦗',\n",
       " ':cricket_game:': '🏏',\n",
       " ':crocodile:': '🐊',\n",
       " ':croissant:': '🥐',\n",
       " ':cross_mark:': '❌',\n",
       " ':cross_mark_button:': '❎',\n",
       " ':crossed_fingers:': '🤞',\n",
       " ':crossed_fingers_dark_skin_tone:': '🤞🏿',\n",
       " ':crossed_fingers_light_skin_tone:': '🤞🏻',\n",
       " ':crossed_fingers_medium-dark_skin_tone:': '🤞🏾',\n",
       " ':crossed_fingers_medium-light_skin_tone:': '🤞🏼',\n",
       " ':crossed_fingers_medium_skin_tone:': '🤞🏽',\n",
       " ':crossed_flags:': '🎌',\n",
       " ':crossed_swords:': '⚔',\n",
       " ':crossed_swords_selector:': '⚔️',\n",
       " ':crown:': '👑',\n",
       " ':crying_cat_face:': '😿',\n",
       " ':crying_face:': '😢',\n",
       " ':crystal_ball:': '🔮',\n",
       " ':cucumber:': '🥒',\n",
       " ':cup_with_straw:': '🥤',\n",
       " ':cupcake:': '🧁',\n",
       " ':curling_stone:': '🥌',\n",
       " ':curly-haired_man:': '👨\\u200d🦱',\n",
       " ':curly-haired_woman:': '👩\\u200d🦱',\n",
       " ':curly_hair:': '🦱',\n",
       " ':curly_loop:': '➰',\n",
       " ':currency_exchange:': '💱',\n",
       " ':curry_rice:': '🍛',\n",
       " ':custard:': '🍮',\n",
       " ':customs:': '🛃',\n",
       " ':cut_of_meat:': '🥩',\n",
       " ':cyclone:': '🌀',\n",
       " ':dagger:': '🗡',\n",
       " ':dagger_selector:': '🗡️',\n",
       " ':dango:': '🍡',\n",
       " ':dark_skin_tone:': '🏿',\n",
       " ':dashing_away:': '💨',\n",
       " ':deaf_man-dark_skin_tone:': '\\U0001f9cf🏿\\u200d♂',\n",
       " ':deaf_man-dark_skin_tone_selector:': '\\U0001f9cf🏿\\u200d♂️',\n",
       " ':deaf_man-light_skin_tone:': '\\U0001f9cf🏻\\u200d♂',\n",
       " ':deaf_man-light_skin_tone_selector:': '\\U0001f9cf🏻\\u200d♂️',\n",
       " ':deaf_man-medium-dark_skin_tone:': '\\U0001f9cf🏾\\u200d♂',\n",
       " ':deaf_man-medium-dark_skin_tone_selector:': '\\U0001f9cf🏾\\u200d♂️',\n",
       " ':deaf_man-medium-light_skin_tone:': '\\U0001f9cf🏼\\u200d♂',\n",
       " ':deaf_man-medium-light_skin_tone_selector:': '\\U0001f9cf🏼\\u200d♂️',\n",
       " ':deaf_man-medium_skin_tone:': '\\U0001f9cf🏽\\u200d♂',\n",
       " ':deaf_man-medium_skin_tone_selector:': '\\U0001f9cf🏽\\u200d♂️',\n",
       " ':deaf_man:': '\\U0001f9cf\\u200d♂',\n",
       " ':deaf_man_selector:': '\\U0001f9cf\\u200d♂️',\n",
       " ':deaf_person-dark_skin_tone:': '\\U0001f9cf🏿',\n",
       " ':deaf_person-light_skin_tone:': '\\U0001f9cf🏻',\n",
       " ':deaf_person-medium-dark_skin_tone:': '\\U0001f9cf🏾',\n",
       " ':deaf_person-medium-light_skin_tone:': '\\U0001f9cf🏼',\n",
       " ':deaf_person-medium_skin_tone:': '\\U0001f9cf🏽',\n",
       " ':deaf_person:': '\\U0001f9cf',\n",
       " ':deaf_woman-dark_skin_tone:': '\\U0001f9cf🏿\\u200d♀',\n",
       " ':deaf_woman-dark_skin_tone_selector:': '\\U0001f9cf🏿\\u200d♀️',\n",
       " ':deaf_woman-light_skin_tone:': '\\U0001f9cf🏻\\u200d♀',\n",
       " ':deaf_woman-light_skin_tone_selector:': '\\U0001f9cf🏻\\u200d♀️',\n",
       " ':deaf_woman-medium-dark_skin_tone:': '\\U0001f9cf🏾\\u200d♀',\n",
       " ':deaf_woman-medium-dark_skin_tone_selector:': '\\U0001f9cf🏾\\u200d♀️',\n",
       " ':deaf_woman-medium-light_skin_tone:': '\\U0001f9cf🏼\\u200d♀',\n",
       " ':deaf_woman-medium-light_skin_tone_selector:': '\\U0001f9cf🏼\\u200d♀️',\n",
       " ':deaf_woman-medium_skin_tone:': '\\U0001f9cf🏽\\u200d♀',\n",
       " ':deaf_woman-medium_skin_tone_selector:': '\\U0001f9cf🏽\\u200d♀️',\n",
       " ':deaf_woman:': '\\U0001f9cf\\u200d♀',\n",
       " ':deaf_woman_selector:': '\\U0001f9cf\\u200d♀️',\n",
       " ':deciduous_tree:': '🌳',\n",
       " ':deer:': '🦌',\n",
       " ':delivery_truck:': '🚚',\n",
       " ':department_store:': '🏬',\n",
       " ':derelict_house:': '🏚',\n",
       " ':derelict_house_selector:': '🏚️',\n",
       " ':desert:': '🏜',\n",
       " ':desert_island:': '🏝',\n",
       " ':desert_island_selector:': '🏝️',\n",
       " ':desert_selector:': '🏜️',\n",
       " ':desktop_computer:': '🖥',\n",
       " ':desktop_computer_selector:': '🖥️',\n",
       " ':detective:': '🕵',\n",
       " ':detective_dark_skin_tone:': '🕵🏿',\n",
       " ':detective_light_skin_tone:': '🕵🏻',\n",
       " ':detective_medium-dark_skin_tone:': '🕵🏾',\n",
       " ':detective_medium-light_skin_tone:': '🕵🏼',\n",
       " ':detective_medium_skin_tone:': '🕵🏽',\n",
       " ':detective_selector:': '🕵️',\n",
       " ':diamond_suit:': '♦',\n",
       " ':diamond_suit_selector:': '♦️',\n",
       " ':diamond_with_a_dot:': '💠',\n",
       " ':dim_button:': '🔅',\n",
       " ':direct_hit:': '🎯',\n",
       " ':disappointed_face:': '😞',\n",
       " ':diving_mask:': '\\U0001f93f',\n",
       " ':diya_lamp:': '\\U0001fa94',\n",
       " ':dizzy:': '💫',\n",
       " ':dizzy_face:': '😵',\n",
       " ':dna:': '🧬',\n",
       " ':dog:': '🐕',\n",
       " ':dog_face:': '🐶',\n",
       " ':dollar_banknote:': '💵',\n",
       " ':dolphin:': '🐬',\n",
       " ':door:': '🚪',\n",
       " ':dotted_six-pointed_star:': '🔯',\n",
       " ':double_curly_loop:': '➿',\n",
       " ':double_exclamation_mark:': '‼',\n",
       " ':double_exclamation_mark_selector:': '‼️',\n",
       " ':doughnut:': '🍩',\n",
       " ':dove:': '🕊',\n",
       " ':dove_selector:': '🕊️',\n",
       " ':down-left_arrow:': '↙',\n",
       " ':down-left_arrow_selector:': '↙️',\n",
       " ':down-right_arrow:': '↘',\n",
       " ':down-right_arrow_selector:': '↘️',\n",
       " ':down_arrow:': '⬇',\n",
       " ':down_arrow_selector:': '⬇️',\n",
       " ':downcast_face_with_sweat:': '😓',\n",
       " ':downwards_button:': '🔽',\n",
       " ':dragon:': '🐉',\n",
       " ':dragon_face:': '🐲',\n",
       " ':dress:': '👗',\n",
       " ':drooling_face:': '🤤',\n",
       " ':drop_of_blood:': '\\U0001fa78',\n",
       " ':droplet:': '💧',\n",
       " ':drum:': '🥁',\n",
       " ':duck:': '🦆',\n",
       " ':dumpling:': '🥟',\n",
       " ':dvd:': '📀',\n",
       " ':e-mail:': '📧',\n",
       " ':eagle:': '🦅',\n",
       " ':ear:': '👂',\n",
       " ':ear_dark_skin_tone:': '👂🏿',\n",
       " ':ear_light_skin_tone:': '👂🏻',\n",
       " ':ear_medium-dark_skin_tone:': '👂🏾',\n",
       " ':ear_medium-light_skin_tone:': '👂🏼',\n",
       " ':ear_medium_skin_tone:': '👂🏽',\n",
       " ':ear_of_corn:': '🌽',\n",
       " ':ear_with_hearing_aid-dark_skin_tone:': '\\U0001f9bb🏿',\n",
       " ':ear_with_hearing_aid-light_skin_tone:': '\\U0001f9bb🏻',\n",
       " ':ear_with_hearing_aid-medium-dark_skin_tone:': '\\U0001f9bb🏾',\n",
       " ':ear_with_hearing_aid-medium-light_skin_tone:': '\\U0001f9bb🏼',\n",
       " ':ear_with_hearing_aid-medium_skin_tone:': '\\U0001f9bb🏽',\n",
       " ':ear_with_hearing_aid:': '\\U0001f9bb',\n",
       " ':egg:': '🥚',\n",
       " ':eggplant:': '🍆',\n",
       " ':eight-pointed_star:': '✴',\n",
       " ':eight-pointed_star_selector:': '✴️',\n",
       " ':eight-spoked_asterisk:': '✳',\n",
       " ':eight-spoked_asterisk_selector:': '✳️',\n",
       " ':eight-thirty:': '🕣',\n",
       " ':eight_o’clock:': '🕗',\n",
       " ':eject_button:': '⏏',\n",
       " ':eject_button_selector:': '⏏️',\n",
       " ':electric_plug:': '🔌',\n",
       " ':elephant:': '🐘',\n",
       " ':eleven-thirty:': '🕦',\n",
       " ':eleven_o’clock:': '🕚',\n",
       " ':elf:': '🧝',\n",
       " ':elf_dark_skin_tone:': '🧝🏿',\n",
       " ':elf_light_skin_tone:': '🧝🏻',\n",
       " ':elf_medium-dark_skin_tone:': '🧝🏾',\n",
       " ':elf_medium-light_skin_tone:': '🧝🏼',\n",
       " ':elf_medium_skin_tone:': '🧝🏽',\n",
       " ':envelope:': '✉',\n",
       " ':envelope_selector:': '✉️',\n",
       " ':envelope_with_arrow:': '📩',\n",
       " ':euro_banknote:': '💶',\n",
       " ':evergreen_tree:': '🌲',\n",
       " ':ewe:': '🐑',\n",
       " ':exclamation_mark:': '❗',\n",
       " ':exclamation_question_mark:': '⁉',\n",
       " ':exclamation_question_mark_selector:': '⁉️',\n",
       " ':exploding_head:': '🤯',\n",
       " ':expressionless_face:': '😑',\n",
       " ':eye:': '👁',\n",
       " ':eye_in_speech_bubble:': '👁\\u200d🗨',\n",
       " ':eye_in_speech_bubble_2:': '👁\\u200d🗨️',\n",
       " ':eye_in_speech_bubble_3:': '👁️\\u200d🗨️',\n",
       " ':eye_in_speech_bubble_selector:': '👁️\\u200d🗨',\n",
       " ':eye_selector:': '👁️',\n",
       " ':eyes:': '👀',\n",
       " ':face_blowing_a_kiss:': '😘',\n",
       " ':face_savoring_food:': '😋',\n",
       " ':face_screaming_in_fear:': '😱',\n",
       " ':face_vomiting:': '🤮',\n",
       " ':face_with_hand_over_mouth:': '🤭',\n",
       " ':face_with_head-bandage:': '🤕',\n",
       " ':face_with_medical_mask:': '😷',\n",
       " ':face_with_monocle:': '🧐',\n",
       " ':face_with_open_mouth:': '😮',\n",
       " ':face_with_raised_eyebrow:': '🤨',\n",
       " ':face_with_rolling_eyes:': '🙄',\n",
       " ':face_with_steam_from_nose:': '😤',\n",
       " ':face_with_symbols_on_mouth:': '🤬',\n",
       " ':face_with_tears_of_joy:': '😂',\n",
       " ':face_with_thermometer:': '🤒',\n",
       " ':face_with_tongue:': '😛',\n",
       " ':face_without_mouth:': '😶',\n",
       " ':factory:': '🏭',\n",
       " ':fairy:': '🧚',\n",
       " ':fairy_dark_skin_tone:': '🧚🏿',\n",
       " ':fairy_light_skin_tone:': '🧚🏻',\n",
       " ':fairy_medium-dark_skin_tone:': '🧚🏾',\n",
       " ':fairy_medium-light_skin_tone:': '🧚🏼',\n",
       " ':fairy_medium_skin_tone:': '🧚🏽',\n",
       " ':falafel:': '\\U0001f9c6',\n",
       " ':fallen_leaf:': '🍂',\n",
       " ':family:': '👪',\n",
       " ':family_man_boy:': '👨\\u200d👦',\n",
       " ':family_man_boy_boy:': '👨\\u200d👦\\u200d👦',\n",
       " ':family_man_girl:': '👨\\u200d👧',\n",
       " ':family_man_girl_boy:': '👨\\u200d👧\\u200d👦',\n",
       " ':family_man_girl_girl:': '👨\\u200d👧\\u200d👧',\n",
       " ':family_man_man_boy:': '👨\\u200d👨\\u200d👦',\n",
       " ':family_man_man_boy_boy:': '👨\\u200d👨\\u200d👦\\u200d👦',\n",
       " ':family_man_man_girl:': '👨\\u200d👨\\u200d👧',\n",
       " ':family_man_man_girl_boy:': '👨\\u200d👨\\u200d👧\\u200d👦',\n",
       " ':family_man_man_girl_girl:': '👨\\u200d👨\\u200d👧\\u200d👧',\n",
       " ':family_man_woman_boy:': '👨\\u200d👩\\u200d👦',\n",
       " ':family_man_woman_boy_boy:': '👨\\u200d👩\\u200d👦\\u200d👦',\n",
       " ':family_man_woman_girl:': '👨\\u200d👩\\u200d👧',\n",
       " ':family_man_woman_girl_boy:': '👨\\u200d👩\\u200d👧\\u200d👦',\n",
       " ':family_man_woman_girl_girl:': '👨\\u200d👩\\u200d👧\\u200d👧',\n",
       " ':family_woman_boy:': '👩\\u200d👦',\n",
       " ':family_woman_boy_boy:': '👩\\u200d👦\\u200d👦',\n",
       " ':family_woman_girl:': '👩\\u200d👧',\n",
       " ':family_woman_girl_boy:': '👩\\u200d👧\\u200d👦',\n",
       " ':family_woman_girl_girl:': '👩\\u200d👧\\u200d👧',\n",
       " ':family_woman_woman_boy:': '👩\\u200d👩\\u200d👦',\n",
       " ':family_woman_woman_boy_boy:': '👩\\u200d👩\\u200d👦\\u200d👦',\n",
       " ':family_woman_woman_girl:': '👩\\u200d👩\\u200d👧',\n",
       " ':family_woman_woman_girl_boy:': '👩\\u200d👩\\u200d👧\\u200d👦',\n",
       " ':family_woman_woman_girl_girl:': '👩\\u200d👩\\u200d👧\\u200d👧',\n",
       " ':fast-forward_button:': '⏩',\n",
       " ':fast_down_button:': '⏬',\n",
       " ':fast_reverse_button:': '⏪',\n",
       " ':fast_up_button:': '⏫',\n",
       " ':fax_machine:': '📠',\n",
       " ':fearful_face:': '😨',\n",
       " ':female_sign:': '♀',\n",
       " ':female_sign_selector:': '♀️',\n",
       " ':ferris_wheel:': '🎡',\n",
       " ':ferry:': '⛴',\n",
       " ':ferry_selector:': '⛴️',\n",
       " ':field_hockey:': '🏑',\n",
       " ':file_cabinet:': '🗄',\n",
       " ':file_cabinet_selector:': '🗄️',\n",
       " ':file_folder:': '📁',\n",
       " ':film_frames:': '🎞',\n",
       " ':film_frames_selector:': '🎞️',\n",
       " ':film_projector:': '📽',\n",
       " ':film_projector_selector:': '📽️',\n",
       " ':fire:': '🔥',\n",
       " ':fire_engine:': '🚒',\n",
       " ':fire_extinguisher:': '🧯',\n",
       " ':firecracker:': '🧨',\n",
       " ':fireworks:': '🎆',\n",
       " ':first_quarter_moon:': '🌓',\n",
       " ':first_quarter_moon_face:': '🌛',\n",
       " ':fish:': '🐟',\n",
       " ':fish_cake_with_swirl:': '🍥',\n",
       " ':fishing_pole:': '🎣',\n",
       " ':five-thirty:': '🕠',\n",
       " ':five_o’clock:': '🕔',\n",
       " ':flag_in_hole:': '⛳',\n",
       " ':flamingo:': '\\U0001f9a9',\n",
       " ':flashlight:': '🔦',\n",
       " ':flat_shoe:': '🥿',\n",
       " ':fleur-de-lis:': '⚜',\n",
       " ':fleur-de-lis_selector:': '⚜️',\n",
       " ':flexed_biceps:': '💪',\n",
       " ':flexed_biceps_dark_skin_tone:': '💪🏿',\n",
       " ':flexed_biceps_light_skin_tone:': '💪🏻',\n",
       " ':flexed_biceps_medium-dark_skin_tone:': '💪🏾',\n",
       " ':flexed_biceps_medium-light_skin_tone:': '💪🏼',\n",
       " ':flexed_biceps_medium_skin_tone:': '💪🏽',\n",
       " ':floppy_disk:': '💾',\n",
       " ':flower_playing_cards:': '🎴',\n",
       " ':flushed_face:': '😳',\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "                    \"3\": \":downcast_face_with_sweat:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                    #\"5\" : \":hundred_points:\",\n",
    "                    #\"6\":\":fire:\",\n",
    "                    #\"7\":\":face_blowing_a_kiss:\",\n",
    "                    #\"8\":\":chestnut:\",\n",
    "                    #\"9\" :\":flexed_biceps:\"\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤️\n",
      "⚾\n",
      "😁\n",
      "😓\n",
      "🍴\n",
      "💯\n",
      "🔥\n",
      "😘\n",
      "🌰\n",
      "💪\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2 Processing custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Desktop/train_emoji.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =pd.read_csv(\"Desktop/test_emoji.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "#lets print sent with emojis\n",
    "data = train.values\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[0]\n",
    "y_train = train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=5)\n",
    "y_test = to_categorical(y_test,num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test[0]\n",
    "y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] 😓\n",
      "['I', 'am', 'proud', 'of', 'your', 'achievements'] 😁\n",
      "['It', 'is', 'the', 'worst', 'day', 'in', 'my', 'life'] 😓\n",
      "['Miss', 'you', 'so', 'much'] ❤️\n",
      "['food', 'is', 'life'] 🍴\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_train[i],emoji.emojize(emoji_dictionary[str(y_train[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Converting sentences into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Desktop/glove.6B.50d.txt\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "cnt = 0\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    #print(word,coefs)\n",
    "    #cnt +=1\n",
    "    #if cnt ==5:\n",
    "        #break\n",
    "    embeddings[word] = coefs    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.4295e-01, -4.2946e-01, -5.4277e-01, -1.0307e+00,  1.2056e+00,\n",
       "       -2.7174e-01, -6.3561e-01, -1.5065e-02,  3.7856e-01,  4.6474e-02,\n",
       "       -1.3102e-01,  6.0500e-01,  1.6391e+00,  2.3940e-01,  1.2128e+00,\n",
       "        8.3178e-01,  7.3893e-01,  1.5200e-01, -1.4175e-01, -8.8384e-01,\n",
       "        2.0829e-02, -3.2545e-01,  1.8035e+00,  1.0045e+00,  5.8484e-01,\n",
       "       -6.2031e-01, -4.3296e-01,  2.3562e-01,  1.3027e+00, -8.1264e-01,\n",
       "        2.3158e+00,  1.1030e+00, -6.0608e-01,  1.0101e+00, -2.2426e-01,\n",
       "        1.8908e-02, -1.0931e-01,  3.8350e-01,  7.7362e-01, -8.1927e-02,\n",
       "       -3.4040e-01, -1.5143e-03, -5.6640e-02,  8.7359e-01,  1.4805e+00,\n",
       "        6.9421e-01, -3.0966e-01, -9.0826e-01,  3.7277e-03,  8.4550e-01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['eat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4 : converting sent into vectors(embedding output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    max_len = 10\n",
    "    emb_dim = 50\n",
    "    embedding_out = np.zeros((X.shape[0],max_len,emb_dim))\n",
    "    for ix in range(X.shape[0]):\n",
    "        #X[ix] = X[ix].split()\n",
    "        for ij in range(len(X[ix])):\n",
    "            #goto every word in the current (ix) sentence\n",
    "            try:\n",
    "                embedding_out[ix][ij] = embeddings[X[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_out[ix][ij] = np.zeros((50,))\n",
    "    return embedding_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_train = embedding_output(x_train)\n",
    "#embedding_test = embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_test = embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 10, 50)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 5 Def the Rnn/LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences = False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6155 - accuracy: 0.2500\n",
      "Epoch 00001: val_loss improved from inf to 1.61762, saving model to best.h5\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 1.6073 - accuracy: 0.2381 - val_loss: 1.6176 - val_accuracy: 0.1852\n",
      "Epoch 2/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5829 - accuracy: 0.3281\n",
      "Epoch 00002: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5875 - accuracy: 0.2762 - val_loss: 1.6323 - val_accuracy: 0.1852\n",
      "Epoch 3/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5367 - accuracy: 0.3594\n",
      "Epoch 00003: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5398 - accuracy: 0.3429 - val_loss: 1.6496 - val_accuracy: 0.2222\n",
      "Epoch 4/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5358 - accuracy: 0.3594\n",
      "Epoch 00004: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5306 - accuracy: 0.3524 - val_loss: 1.6697 - val_accuracy: 0.1481\n",
      "Epoch 5/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5122 - accuracy: 0.3594\n",
      "Epoch 00005: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5039 - accuracy: 0.3429 - val_loss: 1.6825 - val_accuracy: 0.2222\n",
      "Epoch 6/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5057 - accuracy: 0.2812\n",
      "Epoch 00006: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4942 - accuracy: 0.2857 - val_loss: 1.6859 - val_accuracy: 0.2222\n",
      "Epoch 7/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4434 - accuracy: 0.3906\n",
      "Epoch 00007: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4348 - accuracy: 0.4095 - val_loss: 1.6898 - val_accuracy: 0.2222\n",
      "Epoch 8/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4468 - accuracy: 0.4375\n",
      "Epoch 00008: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4378 - accuracy: 0.4381 - val_loss: 1.6848 - val_accuracy: 0.2593\n",
      "Epoch 9/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4110 - accuracy: 0.4219\n",
      "Epoch 00009: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4325 - accuracy: 0.3905 - val_loss: 1.6633 - val_accuracy: 0.2593\n",
      "Epoch 10/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4359 - accuracy: 0.3594\n",
      "Epoch 00010: val_loss did not improve from 1.61762\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3864 - accuracy: 0.3810 - val_loss: 1.6294 - val_accuracy: 0.2222\n",
      "Epoch 11/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4093 - accuracy: 0.3750\n",
      "Epoch 00011: val_loss improved from 1.61762 to 1.59389, saving model to best.h5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.3564 - accuracy: 0.4381 - val_loss: 1.5939 - val_accuracy: 0.2593\n",
      "Epoch 12/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3482 - accuracy: 0.4062\n",
      "Epoch 00012: val_loss improved from 1.59389 to 1.55498, saving model to best.h5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.3152 - accuracy: 0.4381 - val_loss: 1.5550 - val_accuracy: 0.2963\n",
      "Epoch 13/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3409 - accuracy: 0.3906\n",
      "Epoch 00013: val_loss improved from 1.55498 to 1.51247, saving model to best.h5\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.3001 - accuracy: 0.4762 - val_loss: 1.5125 - val_accuracy: 0.2963\n",
      "Epoch 14/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2549 - accuracy: 0.5469\n",
      "Epoch 00014: val_loss improved from 1.51247 to 1.47079, saving model to best.h5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 1.2506 - accuracy: 0.5429 - val_loss: 1.4708 - val_accuracy: 0.2593\n",
      "Epoch 15/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2207 - accuracy: 0.4844\n",
      "Epoch 00015: val_loss improved from 1.47079 to 1.42995, saving model to best.h5\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.1982 - accuracy: 0.5238 - val_loss: 1.4300 - val_accuracy: 0.2222\n",
      "Epoch 16/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1541 - accuracy: 0.4688\n",
      "Epoch 00016: val_loss improved from 1.42995 to 1.40010, saving model to best.h5\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.1075 - accuracy: 0.5143 - val_loss: 1.4001 - val_accuracy: 0.4074\n",
      "Epoch 17/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1181 - accuracy: 0.5156\n",
      "Epoch 00017: val_loss improved from 1.40010 to 1.34388, saving model to best.h5\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0694 - accuracy: 0.5524 - val_loss: 1.3439 - val_accuracy: 0.4444\n",
      "Epoch 18/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0663 - accuracy: 0.5781\n",
      "Epoch 00018: val_loss improved from 1.34388 to 1.29540, saving model to best.h5\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.0329 - accuracy: 0.5619 - val_loss: 1.2954 - val_accuracy: 0.4074\n",
      "Epoch 19/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9815 - accuracy: 0.6250\n",
      "Epoch 00019: val_loss improved from 1.29540 to 1.28182, saving model to best.h5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.9502 - accuracy: 0.6381 - val_loss: 1.2818 - val_accuracy: 0.4074\n",
      "Epoch 20/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9334 - accuracy: 0.6719\n",
      "Epoch 00020: val_loss did not improve from 1.28182\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9022 - accuracy: 0.6857 - val_loss: 1.2841 - val_accuracy: 0.4444\n",
      "Epoch 21/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8151 - accuracy: 0.6875\n",
      "Epoch 00021: val_loss did not improve from 1.28182\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8294 - accuracy: 0.6857 - val_loss: 1.2934 - val_accuracy: 0.4815\n",
      "Epoch 22/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8661 - accuracy: 0.6719\n",
      "Epoch 00022: val_loss improved from 1.28182 to 1.25382, saving model to best.h5\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8457 - accuracy: 0.6762 - val_loss: 1.2538 - val_accuracy: 0.5185\n",
      "Epoch 23/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8031 - accuracy: 0.7188\n",
      "Epoch 00023: val_loss improved from 1.25382 to 1.22885, saving model to best.h5\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.7686 - accuracy: 0.7429 - val_loss: 1.2288 - val_accuracy: 0.5926\n",
      "Epoch 24/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7465 - accuracy: 0.7188\n",
      "Epoch 00024: val_loss improved from 1.22885 to 1.16485, saving model to best.h5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7839 - accuracy: 0.7143 - val_loss: 1.1648 - val_accuracy: 0.5185\n",
      "Epoch 25/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7535 - accuracy: 0.7031\n",
      "Epoch 00025: val_loss improved from 1.16485 to 1.11633, saving model to best.h5\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.7100 - accuracy: 0.7048 - val_loss: 1.1163 - val_accuracy: 0.5185\n",
      "Epoch 26/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6660 - accuracy: 0.7812\n",
      "Epoch 00026: val_loss improved from 1.11633 to 1.07999, saving model to best.h5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6378 - accuracy: 0.7905 - val_loss: 1.0800 - val_accuracy: 0.5926\n",
      "Epoch 27/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6522 - accuracy: 0.7656\n",
      "Epoch 00027: val_loss improved from 1.07999 to 1.07613, saving model to best.h5\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6013 - accuracy: 0.7905 - val_loss: 1.0761 - val_accuracy: 0.6296\n",
      "Epoch 28/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5116 - accuracy: 0.8281\n",
      "Epoch 00028: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5585 - accuracy: 0.8095 - val_loss: 1.1246 - val_accuracy: 0.5926\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6421 - accuracy: 0.8281\n",
      "Epoch 00029: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5700 - accuracy: 0.8190 - val_loss: 1.1603 - val_accuracy: 0.5185\n",
      "Epoch 30/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4119 - accuracy: 0.8906\n",
      "Epoch 00030: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4585 - accuracy: 0.8476 - val_loss: 1.1859 - val_accuracy: 0.5185\n",
      "Epoch 31/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4661 - accuracy: 0.8594\n",
      "Epoch 00031: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4437 - accuracy: 0.8571 - val_loss: 1.1962 - val_accuracy: 0.5556\n",
      "Epoch 32/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4398 - accuracy: 0.8281\n",
      "Epoch 00032: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4464 - accuracy: 0.8286 - val_loss: 1.1902 - val_accuracy: 0.5926\n",
      "Epoch 33/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4344 - accuracy: 0.8750\n",
      "Epoch 00033: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4188 - accuracy: 0.8762 - val_loss: 1.2466 - val_accuracy: 0.5926\n",
      "Epoch 34/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3604 - accuracy: 0.9219\n",
      "Epoch 00034: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3347 - accuracy: 0.9238 - val_loss: 1.3182 - val_accuracy: 0.5556\n",
      "Epoch 35/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4471 - accuracy: 0.8750\n",
      "Epoch 00035: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4165 - accuracy: 0.8857 - val_loss: 1.2792 - val_accuracy: 0.5556\n",
      "Epoch 36/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3489 - accuracy: 0.8906\n",
      "Epoch 00036: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3715 - accuracy: 0.8857 - val_loss: 1.2765 - val_accuracy: 0.5926\n",
      "Epoch 37/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3508 - accuracy: 0.8906\n",
      "Epoch 00037: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3228 - accuracy: 0.9048 - val_loss: 1.1699 - val_accuracy: 0.6296\n",
      "Epoch 38/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2698 - accuracy: 0.9375\n",
      "Epoch 00038: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2296 - accuracy: 0.9429 - val_loss: 1.1967 - val_accuracy: 0.5926\n",
      "Epoch 39/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2436 - accuracy: 0.9219\n",
      "Epoch 00039: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2406 - accuracy: 0.9333 - val_loss: 1.2839 - val_accuracy: 0.5556\n",
      "Epoch 40/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2798 - accuracy: 0.9219\n",
      "Epoch 00040: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2468 - accuracy: 0.9333 - val_loss: 1.2815 - val_accuracy: 0.6296\n",
      "Epoch 41/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2403 - accuracy: 0.9062\n",
      "Epoch 00041: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2387 - accuracy: 0.9143 - val_loss: 1.4020 - val_accuracy: 0.6296\n",
      "Epoch 42/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2470 - accuracy: 0.9375\n",
      "Epoch 00042: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2557 - accuracy: 0.9238 - val_loss: 1.5463 - val_accuracy: 0.5926\n",
      "Epoch 43/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2738 - accuracy: 0.9375\n",
      "Epoch 00043: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2604 - accuracy: 0.9333 - val_loss: 1.5114 - val_accuracy: 0.5926\n",
      "Epoch 44/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1760 - accuracy: 0.9375\n",
      "Epoch 00044: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1701 - accuracy: 0.9429 - val_loss: 1.3965 - val_accuracy: 0.6296\n",
      "Epoch 45/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1251 - accuracy: 0.9844\n",
      "Epoch 00045: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1646 - accuracy: 0.9429 - val_loss: 1.3498 - val_accuracy: 0.6667\n",
      "Epoch 46/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1207 - accuracy: 0.9844\n",
      "Epoch 00046: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1486 - accuracy: 0.9524 - val_loss: 1.3584 - val_accuracy: 0.6667\n",
      "Epoch 47/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1081 - accuracy: 0.9844\n",
      "Epoch 00047: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1274 - accuracy: 0.9714 - val_loss: 1.3361 - val_accuracy: 0.6667\n",
      "Epoch 48/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1191 - accuracy: 0.9844\n",
      "Epoch 00048: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1115 - accuracy: 0.9905 - val_loss: 1.3093 - val_accuracy: 0.7037\n",
      "Epoch 49/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1199 - accuracy: 0.9688\n",
      "Epoch 00049: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1251 - accuracy: 0.9714 - val_loss: 1.3271 - val_accuracy: 0.6667\n",
      "Epoch 50/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1557 - accuracy: 0.9688\n",
      "Epoch 00050: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1177 - accuracy: 0.9810 - val_loss: 1.3582 - val_accuracy: 0.6667\n",
      "Epoch 51/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1170 - accuracy: 0.9844\n",
      "Epoch 00051: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1041 - accuracy: 0.9905 - val_loss: 1.4870 - val_accuracy: 0.6296\n",
      "Epoch 52/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0993 - accuracy: 0.9844\n",
      "Epoch 00052: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0927 - accuracy: 0.9905 - val_loss: 1.7058 - val_accuracy: 0.5926\n",
      "Epoch 53/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1593 - accuracy: 0.9688\n",
      "Epoch 00053: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1273 - accuracy: 0.9810 - val_loss: 1.7579 - val_accuracy: 0.5926\n",
      "Epoch 54/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 00054: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 1.7781 - val_accuracy: 0.5556\n",
      "Epoch 55/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0724 - accuracy: 0.9844\n",
      "Epoch 00055: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0751 - accuracy: 0.9905 - val_loss: 1.8083 - val_accuracy: 0.5926\n",
      "Epoch 56/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0823 - accuracy: 0.9844\n",
      "Epoch 00056: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0865 - accuracy: 0.9810 - val_loss: 1.8203 - val_accuracy: 0.5926\n",
      "Epoch 57/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0642 - accuracy: 0.9844\n",
      "Epoch 00057: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0599 - accuracy: 0.9905 - val_loss: 1.7415 - val_accuracy: 0.6296\n",
      "Epoch 58/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 00058: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0549 - accuracy: 0.9905 - val_loss: 1.7458 - val_accuracy: 0.5926\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0535 - accuracy: 1.0000\n",
      "Epoch 00059: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 2.0821 - val_accuracy: 0.5556\n",
      "Epoch 60/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 00060: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 2.2891 - val_accuracy: 0.5556\n",
      "Epoch 61/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1119 - accuracy: 0.9688\n",
      "Epoch 00061: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1270 - accuracy: 0.9619 - val_loss: 2.0129 - val_accuracy: 0.5926\n",
      "Epoch 62/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0704 - accuracy: 0.9844\n",
      "Epoch 00062: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2267 - accuracy: 0.9524 - val_loss: 1.8981 - val_accuracy: 0.5556\n",
      "Epoch 63/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 00063: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.8946 - val_accuracy: 0.5926\n",
      "Epoch 64/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 00064: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1043 - accuracy: 0.9905 - val_loss: 1.6964 - val_accuracy: 0.5926\n",
      "Epoch 65/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1639 - accuracy: 0.9531\n",
      "Epoch 00065: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1088 - accuracy: 0.9714 - val_loss: 1.3769 - val_accuracy: 0.7037\n",
      "Epoch 66/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1072 - accuracy: 0.9531\n",
      "Epoch 00066: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0931 - accuracy: 0.9619 - val_loss: 1.3908 - val_accuracy: 0.6667\n",
      "Epoch 67/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0777 - accuracy: 0.9844\n",
      "Epoch 00067: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1214 - accuracy: 0.9619 - val_loss: 1.4252 - val_accuracy: 0.6667\n",
      "Epoch 68/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0628 - accuracy: 0.9844\n",
      "Epoch 00068: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0454 - accuracy: 0.9905 - val_loss: 1.2401 - val_accuracy: 0.6667\n",
      "Epoch 69/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0758 - accuracy: 0.9844\n",
      "Epoch 00069: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0631 - accuracy: 0.9810 - val_loss: 1.3988 - val_accuracy: 0.6296\n",
      "Epoch 70/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 00070: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - accuracy: 0.9905 - val_loss: 1.5530 - val_accuracy: 0.5556\n",
      "Epoch 71/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0475 - accuracy: 1.0000\n",
      "Epoch 00071: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 1.6775 - val_accuracy: 0.6296\n",
      "Epoch 72/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 00072: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.7622 - val_accuracy: 0.5926\n",
      "Epoch 73/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0535 - accuracy: 1.0000\n",
      "Epoch 00073: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 0.6296\n",
      "Epoch 74/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.7172 - val_accuracy: 0.6296\n",
      "Epoch 75/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 00075: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0354 - accuracy: 0.9905 - val_loss: 1.7126 - val_accuracy: 0.5556\n",
      "Epoch 76/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.7562 - val_accuracy: 0.5926\n",
      "Epoch 77/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.8198 - val_accuracy: 0.5926\n",
      "Epoch 78/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.8524 - val_accuracy: 0.5926\n",
      "Epoch 79/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.8915 - val_accuracy: 0.5926\n",
      "Epoch 80/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.9402 - val_accuracy: 0.5926\n",
      "Epoch 81/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.9522 - val_accuracy: 0.5926\n",
      "Epoch 82/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.9471 - val_accuracy: 0.6296\n",
      "Epoch 83/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0270 - accuracy: 0.9844\n",
      "Epoch 00083: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0212 - accuracy: 0.9905 - val_loss: 1.9397 - val_accuracy: 0.5926\n",
      "Epoch 84/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 00084: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.9540 - val_accuracy: 0.5556\n",
      "Epoch 85/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0367 - accuracy: 0.9844\n",
      "Epoch 00085: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 1.8855 - val_accuracy: 0.6296\n",
      "Epoch 86/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.8292 - val_accuracy: 0.5926\n",
      "Epoch 87/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.8555 - val_accuracy: 0.5926\n",
      "Epoch 88/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.9315 - val_accuracy: 0.5556\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.9015 - val_accuracy: 0.5556\n",
      "Epoch 90/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.8689 - val_accuracy: 0.5185\n",
      "Epoch 91/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.8363 - val_accuracy: 0.5556\n",
      "Epoch 92/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 1.8395 - val_accuracy: 0.5926\n",
      "Epoch 93/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 00093: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.8523 - val_accuracy: 0.5926\n",
      "Epoch 94/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 00094: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.8795 - val_accuracy: 0.5926\n",
      "Epoch 95/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.9261 - val_accuracy: 0.5926\n",
      "Epoch 96/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.9630 - val_accuracy: 0.5926\n",
      "Epoch 97/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.9884 - val_accuracy: 0.5556\n",
      "Epoch 98/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 00098: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.0207 - val_accuracy: 0.5556\n",
      "Epoch 99/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 00099: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.0631 - val_accuracy: 0.5926\n",
      "Epoch 100/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.0828 - val_accuracy: 0.5556\n",
      "Epoch 101/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 00101: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.0793 - val_accuracy: 0.5556\n",
      "Epoch 102/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 00102: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1067 - val_accuracy: 0.5556\n",
      "Epoch 103/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 00103: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.1198 - val_accuracy: 0.5556\n",
      "Epoch 104/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 00104: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.1343 - val_accuracy: 0.5556\n",
      "Epoch 105/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 00105: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.1368 - val_accuracy: 0.5926\n",
      "Epoch 106/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 00106: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.1315 - val_accuracy: 0.5556\n",
      "Epoch 107/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 00107: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.1368 - val_accuracy: 0.5556\n",
      "Epoch 108/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 00108: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.1305 - val_accuracy: 0.5556\n",
      "Epoch 109/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 00109: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.1441 - val_accuracy: 0.5556\n",
      "Epoch 110/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 00110: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.1796 - val_accuracy: 0.5556\n",
      "Epoch 111/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 00111: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.1734 - val_accuracy: 0.5556\n",
      "Epoch 112/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 00112: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.5556\n",
      "Epoch 113/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 00113: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.1342 - val_accuracy: 0.5556\n",
      "Epoch 114/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00114: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1181 - val_accuracy: 0.5926\n",
      "Epoch 115/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 00115: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0946 - val_accuracy: 0.5926\n",
      "Epoch 116/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00116: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0194 - accuracy: 0.9905 - val_loss: 2.2040 - val_accuracy: 0.5556\n",
      "Epoch 117/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.4126 - val_accuracy: 0.5556\n",
      "Epoch 118/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0247 - accuracy: 0.9844\n",
      "Epoch 00118: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0178 - accuracy: 0.9905 - val_loss: 2.4347 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0442 - accuracy: 0.9844\n",
      "Epoch 00119: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 2.2013 - val_accuracy: 0.5926\n",
      "Epoch 120/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 00120: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0227 - val_accuracy: 0.5926\n",
      "Epoch 121/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 00121: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.8909 - val_accuracy: 0.5556\n",
      "Epoch 122/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 00122: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.6296\n",
      "Epoch 123/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 00123: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.6296\n",
      "Epoch 124/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.6296\n",
      "Epoch 125/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00125: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.8258 - val_accuracy: 0.6667\n",
      "Epoch 126/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0360 - accuracy: 0.9844\n",
      "Epoch 00126: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 0.9905 - val_loss: 1.9566 - val_accuracy: 0.6296\n",
      "Epoch 127/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 00127: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.1088 - val_accuracy: 0.5926\n",
      "Epoch 128/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.2447 - val_accuracy: 0.5556\n",
      "Epoch 129/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.3465 - val_accuracy: 0.5556\n",
      "Epoch 130/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.3681 - val_accuracy: 0.5556\n",
      "Epoch 131/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00131: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.3049 - val_accuracy: 0.5556\n",
      "Epoch 132/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.2952 - val_accuracy: 0.5556\n",
      "Epoch 133/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.2757 - val_accuracy: 0.5556\n",
      "Epoch 134/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00134: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.2349 - val_accuracy: 0.5556\n",
      "Epoch 135/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1616 - val_accuracy: 0.5556\n",
      "Epoch 136/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00136: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.0938 - val_accuracy: 0.5926\n",
      "Epoch 137/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 00137: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.0678 - val_accuracy: 0.5926\n",
      "Epoch 138/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 00138: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.0643 - val_accuracy: 0.5926\n",
      "Epoch 139/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 00139: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.0577 - val_accuracy: 0.5926\n",
      "Epoch 140/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 00140: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.0743 - val_accuracy: 0.5926\n",
      "Epoch 141/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0958 - val_accuracy: 0.5926\n",
      "Epoch 142/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00142: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1210 - val_accuracy: 0.5926\n",
      "Epoch 143/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 00143: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.5926\n",
      "Epoch 144/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00144: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.5926\n",
      "Epoch 145/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 00145: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1676 - val_accuracy: 0.5926\n",
      "Epoch 146/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00146: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1708 - val_accuracy: 0.5926\n",
      "Epoch 147/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00147: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2044 - val_accuracy: 0.5926\n",
      "Epoch 148/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00148: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.2369 - val_accuracy: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 00149: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2726 - val_accuracy: 0.5926\n",
      "Epoch 150/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 00150: val_loss did not improve from 1.07613\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.3080 - val_accuracy: 0.5926\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "early = EarlyStopping(patience=10,monitor='val_accuracy')\n",
    "check = ModelCheckpoint(\"best.h5\",monitor='val_loss',verbose=True,save_best_only=True)\n",
    "hist = model.fit(embedding_train,y_train,epochs=150,batch_size=64,shuffle=True,\n",
    "                validation_split=0.2,callbacks=[check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embedding_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 2, 2, 2, 1, 2, 4, 3, 1, 2, 0, 3, 1, 3, 2, 2, 3, 2, 0, 3,\n",
       "       4, 2, 3, 1, 2, 0, 1, 2, 0, 1, 0, 2, 0, 1, 2, 4, 1, 2, 1, 0, 0, 1,\n",
       "       2, 2, 2, 2, 3, 1, 3, 0, 3, 2, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1869 - accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1869049072265625, 0.625]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embedding_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iwanttoeat\n",
      "🍴\n",
      "🍴\n",
      "hedidnotanswer\n",
      "😓\n",
      "😓\n",
      "hegotaraise\n",
      "😁\n",
      "😓\n",
      "shegotmeapresent\n",
      "❤️\n",
      "😁\n",
      "hahahaitwassofunny\n",
      "😁\n",
      "😁\n",
      "heisagoodfriend\n",
      "❤️\n",
      "😁\n",
      "Iamupset\n",
      "❤️\n",
      "⚾\n",
      "Wehadsuchalovelydinnertonight\n",
      "❤️\n",
      "😁\n",
      "whereisthefood\n",
      "🍴\n",
      "🍴\n",
      "Stopmakingthisjokehahaha\n",
      "😁\n",
      "😓\n",
      "whereistheball\n",
      "⚾\n",
      "⚾\n",
      "workishard\n",
      "😓\n",
      "😁\n",
      "Thisgirlismessingwithme\n",
      "😓\n",
      "❤️\n",
      "areyouserioushaha\n",
      "😁\n",
      "😓\n",
      "Letusgoplaybaseball\n",
      "⚾\n",
      "⚾\n",
      "Thisstupidgraderisnotworking\n",
      "😓\n",
      "😓\n",
      "workishorrible\n",
      "😓\n",
      "😁\n",
      "Congratulationforhavingababy\n",
      "😁\n",
      "😁\n",
      "stopmessingaround\n",
      "😓\n",
      "😓\n",
      "anysuggestionsfordinner\n",
      "🍴\n",
      "😁\n",
      "Ilovetakingbreaks\n",
      "❤️\n",
      "❤️\n",
      "youbrightenmyday\n",
      "😁\n",
      "😓\n",
      "Iboiledrice\n",
      "🍴\n",
      "🍴\n",
      "sheisabully\n",
      "😓\n",
      "😁\n",
      "Whyareyoufeelingbad\n",
      "😓\n",
      "😓\n",
      "Iamupset\n",
      "😓\n",
      "⚾\n",
      "Iworkedduringmybirthday\n",
      "😓\n",
      "😁\n",
      "Mygrandmotheristheloveofmylife\n",
      "❤️\n",
      "❤️\n",
      "enjoyyourbreak\n",
      "😁\n",
      "⚾\n",
      "valentinedayisnear\n",
      "❤️\n",
      "😁\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(''.join(x_test[i]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(y_test[i]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = \n",
    "cm = confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
